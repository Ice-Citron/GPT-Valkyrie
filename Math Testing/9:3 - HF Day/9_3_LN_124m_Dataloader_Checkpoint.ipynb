{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqPGMHjAkLR4"
      },
      "outputs": [],
      "source": [
        "class DataLoaderLite:\n",
        "    def __init__(self, B, T, process_rank, num_processes, split):\n",
        "        # ... (other initialization code)\n",
        "        self.current_shard = 0\n",
        "        self.current_position = self.B * self.T * self.process_rank\n",
        "\n",
        "    def next_batch(self):\n",
        "        B, T = self.B, self.T\n",
        "        buf = self.tokens[self.current_position : self.current_position+B*T+1]\n",
        "        x = (buf[:-1]).view(B, T) # inputs\n",
        "        y = (buf[1:]).view(B, T) # targets\n",
        "        # Advance the position in the tensor\n",
        "        self.current_position += B * T * self.num_processes\n",
        "        # If loading the next batch would be out of bounds, advance to next shard\n",
        "        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):\n",
        "            self.current_shard = (self.current_shard + 1) % len(self.shards)\n",
        "            self.tokens = load_tokens(self.shards[self.current_shard])\n",
        "            self.current_position = B * T * self.process_rank\n",
        "        return x, y\n",
        "\n",
        "    def set_state(self, state):\n",
        "        self.current_shard = state['current_shard']\n",
        "        self.current_position = state['current_position']\n",
        "        self.tokens = load_tokens(self.shards[self.current_shard])\n",
        "\n",
        "    def get_state(self):\n",
        "        return {\n",
        "            'current_shard': self.current_shard,\n",
        "            'current_position': self.current_position\n",
        "        }\n",
        "\n",
        "# In the training loop:\n",
        "if args.resume_from_checkpoint:\n",
        "    latest_checkpoint = max([f for f in os.listdir(log_dir) if f.startswith(\"checkpoint\")], key=os.path.getctime)\n",
        "    checkpoint_path = os.path.join(log_dir, latest_checkpoint)\n",
        "    starting_step, val_loss, run_name = load_checkpoint(checkpoint_path, raw_model, optimizer, lr_scheduler, train_loader, val_loader)\n",
        "    print(f\"Resuming from checkpoint at step {starting_step}\")\n",
        "else:\n",
        "    starting_step = 0\n",
        "    # ... (setup for new run)\n",
        "\n",
        "for step in range(starting_step, max_steps):\n",
        "    # Get the next batch of data\n",
        "    x, y = train_loader.next_batch()\n",
        "\n",
        "    # ... (rest of the training loop)\n",
        "\n",
        "    if step % 2000 == 0 or last_step:\n",
        "        # Save checkpoint\n",
        "        checkpoint_path = save_checkpoint(\n",
        "            raw_model, optimizer, lr_scheduler, step, val_loss_accum.item(), run_name,\n",
        "            train_loader.get_state(), val_loader.get_state()\n",
        "        )\n",
        "        # ... (push to HuggingFace, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting to Config for train_gpt2.py"
      ],
      "metadata": {
        "id": "48kMdR_GlyPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To modify your train_gpt2.py file so that the main hyperparameters are controlled from the config dictionary instead of having integer variables scattered throughout the code, you can make the following changes:\n",
        "\n",
        "1. Update the config dictionary to include all the main hyperparameters:\n",
        "\n",
        "```python\n",
        "config = {\n",
        "    \"batch_size\": 64,\n",
        "    \"weight_decay\": 0.1,\n",
        "    \"learning_rate\": 6e-4,\n",
        "    \"lr_scheduler_type\": \"cosine\",\n",
        "    \"num_warmup_steps\": 715,\n",
        "    \"gradient_accumulation_steps\": 2**19 // (64 * 1024 * ddp_world_size),\n",
        "    \"max_train_steps\": 19073,\n",
        "    \"max_eval_steps\": 20,\n",
        "    \"seq_length\": 1024,\n",
        "    \"seed\": 1,\n",
        "    \"eval_interval\": 250,\n",
        "    \"save_interval\": 2000,\n",
        "    \"total_batch_size\": 524288,\n",
        "    \"max_lr\": 6e-4,\n",
        "    \"min_lr\": 6e-5,\n",
        "}\n",
        "```\n",
        "\n",
        "2. Replace the hardcoded values in your code with references to the config dictionary. Here are some examples:\n",
        "\n",
        "```python\n",
        "# Replace\n",
        "B = 64\n",
        "T = 1024\n",
        "\n",
        "# With\n",
        "B = config[\"batch_size\"]\n",
        "T = config[\"seq_length\"]\n",
        "\n",
        "# Replace\n",
        "total_batch_size = 524288\n",
        "\n",
        "# With\n",
        "total_batch_size = config[\"total_batch_size\"]\n",
        "\n",
        "# Replace\n",
        "grad_accum_steps = total_batch_size // (B * T * ddp_world_size)\n",
        "\n",
        "# With\n",
        "grad_accum_steps = config[\"gradient_accumulation_steps\"]\n",
        "\n",
        "# Replace\n",
        "max_lr = 6e-4\n",
        "min_lr = max_lr * 0.1\n",
        "warmup_steps = 715\n",
        "max_steps = 19073\n",
        "\n",
        "# With\n",
        "max_lr = config[\"max_lr\"]\n",
        "min_lr = config[\"min_lr\"]\n",
        "warmup_steps = config[\"num_warmup_steps\"]\n",
        "max_steps = config[\"max_train_steps\"]\n",
        "\n",
        "# Replace\n",
        "if step % 250 == 0 or last_step:\n",
        "\n",
        "# With\n",
        "if step % config[\"eval_interval\"] == 0 or last_step:\n",
        "\n",
        "# Replace\n",
        "if step % 2000 == 0 or last_step:\n",
        "\n",
        "# With\n",
        "if step % config[\"save_interval\"] == 0 or last_step:\n",
        "```\n",
        "\n",
        "3. Update the learning rate scheduler function:\n",
        "\n",
        "```python\n",
        "def get_lr(it):\n",
        "    if it < config[\"num_warmup_steps\"]:\n",
        "        return config[\"max_lr\"] * (it+1) / config[\"num_warmup_steps\"]\n",
        "    if it > config[\"max_train_steps\"]:\n",
        "        return config[\"min_lr\"]\n",
        "    decay_ratio = (it - config[\"num_warmup_steps\"]) / (config[\"max_train_steps\"] - config[\"num_warmup_steps\"])\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "    return config[\"min_lr\"] + coeff * (config[\"max_lr\"] - config[\"min_lr\"])\n",
        "```\n",
        "\n",
        "4. Update the optimizer configuration:\n",
        "\n",
        "```python\n",
        "optimizer = raw_model.configure_optimizers(\n",
        "    weight_decay=config[\"weight_decay\"],\n",
        "    learning_rate=config[\"learning_rate\"],\n",
        "    device_type=device_type\n",
        ")\n",
        "```\n",
        "\n",
        "5. Update the evaluation loop:\n",
        "\n",
        "```python\n",
        "val_loss_steps = config[\"max_eval_steps\"]\n",
        "for _ in range(val_loss_steps):\n",
        "    # ... (rest of the evaluation loop)\n",
        "```\n",
        "\n",
        "By making these changes, you'll centralize all the main hyperparameters in the config dictionary, making it easier to modify and experiment with different settings. This approach also makes your code more maintainable and reduces the risk of inconsistencies between different parts of your script."
      ],
      "metadata": {
        "id": "9X5HZdl2l2Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're right, and I apologize for the oversight. The `load_checkpoint` function you defined isn't being used in the code snippet you've shown. This is likely the reason why your training isn't resuming from the checkpoint as expected.\n",
        "\n",
        "To fix this, you should modify your code to use the `load_checkpoint` function. Here's how you can integrate it into your existing code:\n",
        "\n",
        "```python\n",
        "if args.resume_from_checkpoint:\n",
        "    checkpoint_dir = \"./log\"\n",
        "    checkpoint_pattern = os.path.join(checkpoint_dir, \"checkpoint_*.pt\")\n",
        "    checkpoint_files = glob.glob(checkpoint_pattern)\n",
        "    \n",
        "    if not checkpoint_files:\n",
        "        print(f\"No checkpoint files found in {checkpoint_dir}\")\n",
        "        # Handle the case when no checkpoints are found (e.g., start from scratch)\n",
        "    else:\n",
        "        latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
        "        checkpoint_path = latest_checkpoint\n",
        "        \n",
        "        # Use the load_checkpoint function here\n",
        "        starting_step, val_loss, run_name = load_checkpoint(checkpoint_path, raw_model, optimizer, train_loader, val_loader)\n",
        "        \n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        wandb_id = checkpoint['wandb_id']\n",
        "        \n",
        "        logger, run_name = resume_logging(project_name.split(\"/\")[1], wandb_id, args)\n",
        "        print(f\"Resuming from checkpoint: {checkpoint_path}\")\n",
        "        print(f\"Weights and Biases run name: {run_name}\")\n",
        "        print(f\"Resuming from step: {starting_step}\")\n",
        "\n",
        "        # Initialize HuggingFace repository <-- UNSURE IF NEEDED\n",
        "        if master_process:\n",
        "            new_branch_name = run_name\n",
        "            create_branch(project_name, repo_type=\"model\", branch=new_branch_name)\n",
        "            hf_repo = Repository(\"./\", clone_from=project_name, revision=run_name)\n",
        "\n",
        "        if master_process:\n",
        "            print(f\"Resuming from checkpoint at step {starting_step}\")\n",
        "```\n",
        "\n",
        "This modification does the following:\n",
        "\n",
        "1. It uses your `load_checkpoint` function to load the model state, optimizer state, and data loader states.\n",
        "2. It retrieves the starting step, validation loss, and run name from the checkpoint.\n",
        "3. It still loads the full checkpoint to get the `wandb_id`.\n",
        "\n",
        "Also, make sure that in your training loop, you're starting from `starting_step` instead of 0:\n",
        "\n",
        "```python\n",
        "for step in range(starting_step, max_steps):\n",
        "    # Your training code here\n",
        "```\n",
        "\n",
        "This should ensure that your training resumes from the correct step when loading a checkpoint.\n",
        "\n",
        "Remember to also update your `save_checkpoint` function to include all necessary information:\n",
        "\n",
        "```python\n",
        "def save_checkpoint(model, optimizer, step, val_loss, run_name, train_loader_state, val_loader_state, wandb_id):\n",
        "    checkpoint = {\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'step': step,\n",
        "        'val_loss': val_loss,\n",
        "        'run_name': run_name,\n",
        "        'train_loader_state': train_loader_state,\n",
        "        'val_loader_state': val_loader_state,\n",
        "        'wandb_id': wandb_id\n",
        "    }\n",
        "    checkpoint_path = os.path.join(\"./log\", f\"checkpoint_{step:05d}.pt\")\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    return checkpoint_path\n",
        "```\n",
        "\n",
        "These changes should help your training resume correctly from the checkpoint."
      ],
      "metadata": {
        "id": "eiB24cNIAU5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torchrun --standalone --nproc_per_node=1 train_gpt2-trail.py\n",
        "\n",
        "torchrun --standalone --nproc_per_node=6 train_gpt2-final.py"
      ],
      "metadata": {
        "id": "tbTdw6E_pM5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# task for tommorow\n",
        "\n",
        "- get model converted and usable by HF\n",
        "- fix and clear training files\n",
        "- get RMSN trained\n",
        "- check PN\n",
        "\n",
        "---\n",
        "\n",
        "- close GPU when leave"
      ],
      "metadata": {
        "id": "tmvinzv3CyUf"
      }
    }
  ]
}