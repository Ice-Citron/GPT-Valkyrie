{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BillSum"
      ],
      "metadata": {
        "id": "j-NzkII8GmEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pingouin\n",
        "!pip install scikit_posthocs\n",
        "!pip install krippendorff"
      ],
      "metadata": {
        "id": "zDYrJ98e4w2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa2da0d-611d-4e39-805e-4d2ba30c8772"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pingouin\n",
            "  Downloading pingouin-0.5.5-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pingouin) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from pingouin) (2.2.2)\n",
            "Collecting pandas-flavor (from pingouin)\n",
            "  Downloading pandas_flavor-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pingouin) (1.13.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.13.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.14.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pingouin) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->pingouin) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->pingouin) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->pingouin) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->pingouin) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->pingouin) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pingouin) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pingouin) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pingouin) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pingouin) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pingouin) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pingouin) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pingouin) (3.2.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from pandas-flavor->pingouin) (2024.9.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->pingouin) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->pingouin) (1.16.0)\n",
            "Downloading pingouin-0.5.5-py3-none-any.whl (204 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.4/204.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas_flavor-0.6.0-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: pandas-flavor, pingouin\n",
            "Successfully installed pandas-flavor-0.6.0 pingouin-0.5.5\n",
            "Collecting scikit_posthocs\n",
            "  Downloading scikit_posthocs-0.9.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (1.13.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (0.14.4)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->scikit_posthocs) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->scikit_posthocs) (1.16.0)\n",
            "Downloading scikit_posthocs-0.9.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: scikit_posthocs\n",
            "Successfully installed scikit_posthocs-0.9.1\n",
            "Collecting krippendorff\n",
            "  Downloading krippendorff-0.8.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from krippendorff) (1.26.4)\n",
            "Downloading krippendorff-0.8.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: krippendorff\n",
            "Successfully installed krippendorff-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def process_csv(eval_file, gen_file):\n",
        "    eval_df = pd.read_csv(eval_file)\n",
        "    gen_df = pd.read_csv(gen_file)\n",
        "\n",
        "    # Ensure the dataframes have the same number of rows\n",
        "    min_rows = min(len(eval_df), len(gen_df))\n",
        "    eval_df = eval_df.iloc[:min_rows]\n",
        "    gen_df = gen_df.iloc[:min_rows]\n",
        "\n",
        "    # Merge the dataframes\n",
        "    merged_df = pd.merge(eval_df, gen_df[['truncated_input', 'generated_summary']], left_index=True, right_index=True)\n",
        "\n",
        "    # Add model_name, norm_type, and variant columns from gen_df\n",
        "    merged_df['model_name'] = gen_df['model_name']\n",
        "    merged_df['norm_type'] = gen_df['norm_type']\n",
        "    merged_df['variant'] = gen_df['variant']\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "def main():\n",
        "    evaluation_files = [\n",
        "        'LN_AttnOnly_gpt4_summary_parsed_evaluations.csv',\n",
        "        'LN_FFNonly_gpt4_summary_parsed_evaluations.csv',\n",
        "        'LN_baseModel_gpt4_summary_parsed_evaluations.csv',\n",
        "        'LN_noNorm_gpt4_summary_parsed_evaluations.csv',\n",
        "        'RMSN_AttnOnly_gpt4_summary_parsed_evaluations.csv',\n",
        "        'RMSN_FFNonly_gpt4_summary_parsed_evaluations.csv',\n",
        "        'RMSN_baseModel_gpt4_summary_parsed_evaluations.csv',\n",
        "        'RMSN_noNorm_gpt4_summary_parsed_evaluations.csv'\n",
        "    ]\n",
        "\n",
        "    generated_summary_files = [\n",
        "        'LN_AttnOnly_evaluation_data_modified.csv',\n",
        "        'LN_FFNonly_evaluation_data_modified.csv',\n",
        "        'LN_baseModel_evaluation_data_modified.csv',\n",
        "        'LN_noNorm_evaluation_data_modified.csv',\n",
        "        'RMSN_AttnOnly_evaluation_data_modified.csv',\n",
        "        'RMSN_FFNonly_evaluation_data_modified.csv',\n",
        "        'RMSN_baseModel_evaluation_data_modified.csv',\n",
        "        'RMSN_noNorm_evaluation_data_modified.csv'\n",
        "    ]\n",
        "\n",
        "    all_data = pd.concat([process_csv(eval_file, gen_file)\n",
        "                          for eval_file, gen_file in zip(evaluation_files, generated_summary_files)],\n",
        "                         ignore_index=True)\n",
        "\n",
        "    columns_order = ['model_name', 'norm_type', 'variant', 'truncated_input', 'generated_summary',\n",
        "                     'Overall Score', 'Relevance Score', 'Conciseness Score', 'Fluency Score',\n",
        "                     'Accuracy Score', 'Coherence Score', 'Overall Feedback', 'Comments on Columns']\n",
        "\n",
        "    all_data = all_data[columns_order]\n",
        "\n",
        "    # Truncate generated_summary to 1000 characters\n",
        "    all_data['generated_summary'] = all_data['generated_summary'].str[:1000]\n",
        "\n",
        "    # Save the entire dataframe to a single CSV file\n",
        "    output_file = 'combined_data_truncated.csv'\n",
        "    all_data.to_csv(output_file, index=False)\n",
        "    print(f\"All data has been saved to '{output_file}' with generated summary truncated to 1000 characters.\")\n",
        "\n",
        "    print(f\"The file contains {len(all_data)} rows and {len(all_data.columns)} columns.\")\n",
        "    print(\"Columns:\", ', '.join(all_data.columns))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi7TKpuFBDw3",
        "outputId": "32350108-c462-4b2b-a268-03402acb74f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All data has been saved to 'combined_data_truncated.csv' with generated summary truncated to 1000 characters.\n",
            "The file contains 200 rows and 13 columns.\n",
            "Columns: model_name, norm_type, variant, truncated_input, generated_summary, Overall Score, Relevance Score, Conciseness Score, Fluency Score, Accuracy Score, Coherence Score, Overall Feedback, Comments on Columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "def load_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"Loaded {len(df)} rows of data\")\n",
        "    print(f\"Columns: {', '.join(df.columns)}\")\n",
        "    return df\n",
        "\n",
        "def calculate_statistics(df):\n",
        "    score_columns = ['Overall Score', 'Relevance Score', 'Conciseness Score',\n",
        "                     'Fluency Score', 'Accuracy Score', 'Coherence Score']\n",
        "    return df.groupby(['model_name', 'norm_type', 'variant'])[score_columns].agg(['mean', 'std', 'min', 'max'])\n",
        "\n",
        "def perform_anova(df, score_column):\n",
        "    models = df['model_name'].unique()\n",
        "    data = [df[df['model_name'] == model][score_column] for model in models]\n",
        "    f_value, p_value = stats.f_oneway(*data)\n",
        "    return f_value, p_value\n",
        "\n",
        "def create_collated_boxplots(df, output_dir):\n",
        "    score_columns = ['Overall Score', 'Relevance Score', 'Conciseness Score',\n",
        "                     'Fluency Score', 'Accuracy Score', 'Coherence Score']\n",
        "\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    for i, score in enumerate(score_columns, 1):\n",
        "        plt.subplot(2, 3, i)\n",
        "        sns.boxplot(x='model_name', y=score, hue='norm_type', data=df)\n",
        "        plt.title(score)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.xlabel('')\n",
        "        if i % 3 != 1:\n",
        "            plt.ylabel('')\n",
        "        if i == 3:\n",
        "            plt.legend(title='Norm Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        else:\n",
        "            plt.legend([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'summarization_collated_boxplots.png'), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    output_dir = 'analysis_results'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    df = load_data('combined_data_truncated.csv')\n",
        "\n",
        "    stats_df = calculate_statistics(df)\n",
        "    stats_df.to_csv(os.path.join(output_dir, 'descriptive_statistics.csv'))\n",
        "\n",
        "    create_collated_boxplots(df, output_dir)\n",
        "\n",
        "    score_columns = ['Overall Score', 'Relevance Score', 'Conciseness Score',\n",
        "                     'Fluency Score', 'Accuracy Score', 'Coherence Score']\n",
        "    anova_results = []\n",
        "    for score in score_columns:\n",
        "        f_value, p_value = perform_anova(df, score)\n",
        "        anova_results.append({\n",
        "            'Metric': score,\n",
        "            'F-value': f_value,\n",
        "            'p-value': p_value\n",
        "        })\n",
        "\n",
        "    anova_df = pd.DataFrame(anova_results)\n",
        "    anova_df.to_csv(os.path.join(output_dir, 'summarization_anova_results.csv'), index=False)\n",
        "\n",
        "    print(\"Analysis complete. Results saved in 'analysis_results' directory.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je2IhPlcAd3A",
        "outputId": "edee7c4a-0549-4efe-90a3-9f9210f5c3d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 200 rows of data\n",
            "Columns: model_name, norm_type, variant, truncated_input, generated_summary, Overall Score, Relevance Score, Conciseness Score, Fluency Score, Accuracy Score, Coherence Score, Overall Feedback, Comments on Columns\n",
            "Analysis complete. Results saved in 'analysis_results' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import kruskal\n",
        "from scikit_posthocs import posthoc_dunn\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('combined_data_truncated.csv')\n",
        "\n",
        "print(\"Columns in the CSV file:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Ensure 'model_name' is treated as a categorical variable\n",
        "df['model_name'] = df['model_name'].astype('category')\n",
        "\n",
        "# Define new score columns\n",
        "score_columns = ['Overall Score', 'Relevance Score', 'Conciseness Score', 'Fluency Score', 'Accuracy Score', 'Coherence Score']\n",
        "\n",
        "print(f\"\\nUsing score columns: {score_columns}\")\n",
        "\n",
        "# 1. Effect Size Calculation\n",
        "def calculate_effect_size(df, metric):\n",
        "    try:\n",
        "        f_value, _ = stats.f_oneway(*[group[metric] for name, group in df.groupby('model_name')])\n",
        "        return f_value / (f_value + df.groupby('model_name').size().iloc[0] - 1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating effect size for {metric}: {e}\")\n",
        "        return np.nan\n",
        "\n",
        "effect_sizes = {metric: calculate_effect_size(df, metric) for metric in score_columns}\n",
        "print(\"\\nEffect Sizes (Eta Squared):\")\n",
        "print(pd.Series(effect_sizes))\n",
        "\n",
        "# 2. Post-hoc Tests\n",
        "def perform_tukey_hsd(df, metric):\n",
        "    try:\n",
        "        tukey = pairwise_tukeyhsd(df[metric], df['model_name'])\n",
        "        return pd.DataFrame(data=tukey._results_table.data[1:], columns=tukey._results_table.data[0])\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing Tukey HSD for {metric}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "tukey_results = {metric: perform_tukey_hsd(df, metric) for metric in score_columns}\n",
        "print(f\"\\nTukey HSD Results (example for {score_columns[0]}):\")\n",
        "print(tukey_results[score_columns[0]])\n",
        "\n",
        "# 3. Correlation Analysis\n",
        "correlation_matrix = df[score_columns].corr()\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# 4. Principal Component Analysis\n",
        "scaler = StandardScaler()\n",
        "pca = PCA()\n",
        "pca_result = pca.fit_transform(scaler.fit_transform(df[score_columns]))\n",
        "print(\"\\nPCA Explained Variance Ratio:\")\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "# 5. Non-parametric Tests\n",
        "def perform_kruskal_dunn(df, metric):\n",
        "    try:\n",
        "        kruskal_result = kruskal(*[group[metric].values for name, group in df.groupby('model_name')])\n",
        "        if kruskal_result.pvalue < 0.05:\n",
        "            dunn_result = posthoc_dunn(df, val_col=metric, group_col='model_name', p_adjust='bonferroni')\n",
        "            return kruskal_result, dunn_result\n",
        "        return kruskal_result, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing Kruskal-Wallis and Dunn's test for {metric}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "kruskal_dunn_results = {metric: perform_kruskal_dunn(df, metric) for metric in score_columns}\n",
        "print(f\"\\nKruskal-Wallis and Dunn's Test Results (example for {score_columns[0]}):\")\n",
        "print(f\"Kruskal-Wallis: {kruskal_dunn_results[score_columns[0]][0]}\")\n",
        "print(\"Dunn's Test:\")\n",
        "print(kruskal_dunn_results[score_columns[0]][1])\n",
        "\n",
        "# 6. Visualizations\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap of Metrics')\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap_new_metrics.png')\n",
        "plt.close()\n",
        "\n",
        "# Violin Plots\n",
        "plt.figure(figsize=(20, 15))\n",
        "for i, metric in enumerate(score_columns, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.violinplot(x='model_name', y=metric, data=df)\n",
        "    plt.title(metric)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.xlabel('')\n",
        "    if i % 3 != 1:\n",
        "        plt.ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('violin_plots_new_metrics.png', bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Radar Chart\n",
        "def radar_chart(df, metrics):\n",
        "    means = df.groupby('model_name')[metrics].mean()\n",
        "    angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False)\n",
        "    means = pd.concat([means, means.iloc[:, :1]], axis=1)\n",
        "    angles = np.concatenate((angles, [angles[0]]))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 10), subplot_kw=dict(projection='polar'))\n",
        "    for model in means.index:\n",
        "        values = means.loc[model].values\n",
        "        ax.plot(angles, values, 'o-', linewidth=2, label=model)\n",
        "        ax.fill(angles, values, alpha=0.25)\n",
        "    ax.set_thetagrids(angles[:-1] * 180/np.pi, metrics)\n",
        "    ax.set_ylim(0, 5)  # Assuming scores are between 0 and 5\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
        "    plt.title(\"Model Performance Across New Metrics\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('radar_chart_new_metrics.png', bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "radar_chart(df, score_columns)\n",
        "\n",
        "# Distribution of Scores\n",
        "plt.figure(figsize=(20, 15))\n",
        "for i, metric in enumerate(score_columns, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    for model in df['model_name'].unique():\n",
        "        sns.kdeplot(data=df[df['model_name'] == model], x=metric, label=model)\n",
        "    plt.title(f'Distribution of {metric}')\n",
        "    plt.xlabel('Score')\n",
        "    plt.ylabel('Density')\n",
        "    if i == 3:  # Place legend outside the plots\n",
        "        plt.legend(title='Model Name', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    else:\n",
        "        plt.legend([])  # Remove individual legends\n",
        "plt.tight_layout()\n",
        "plt.savefig('score_distributions_new_metrics.png', bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Boxplots\n",
        "plt.figure(figsize=(20, 15))\n",
        "for i, metric in enumerate(score_columns, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(x='model_name', y=metric, data=df)\n",
        "    plt.title(metric)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.xlabel('')\n",
        "    if i % 3 != 1:\n",
        "        plt.ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('boxplots_new_metrics.png', bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nVisualizations complete. Check the generated PNG files for updated plots.\")\n",
        "\n",
        "# 7. Basic Descriptive Statistics\n",
        "descriptive_stats = df.groupby('model_name')[score_columns].agg(['mean', 'std', 'min', 'max'])\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(descriptive_stats)\n",
        "\n",
        "print(\"\\nAnalysis complete. Check the generated PNG files for visualizations.\")"
      ],
      "metadata": {
        "id": "dBUdFQrAAd00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37330833-5cf0-4dfd-942e-99aec0259dd5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the CSV file:\n",
            "Index(['model_name', 'norm_type', 'variant', 'truncated_input',\n",
            "       'generated_summary', 'Overall Score', 'Relevance Score',\n",
            "       'Conciseness Score', 'Fluency Score', 'Accuracy Score',\n",
            "       'Coherence Score', 'Overall Feedback', 'Comments on Columns'],\n",
            "      dtype='object')\n",
            "\n",
            "Using score columns: ['Overall Score', 'Relevance Score', 'Conciseness Score', 'Fluency Score', 'Accuracy Score', 'Coherence Score']\n",
            "\n",
            "Effect Sizes (Eta Squared):\n",
            "Overall Score        0.023352\n",
            "Relevance Score      0.070312\n",
            "Conciseness Score    0.046649\n",
            "Fluency Score        0.072741\n",
            "Accuracy Score       0.052493\n",
            "Coherence Score      0.043075\n",
            "dtype: float64\n",
            "\n",
            "Tukey HSD Results (example for Overall Score):\n",
            "                                               group1  \\\n",
            "0    shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum   \n",
            "1    shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum   \n",
            "2    shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum   \n",
            "3    shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum   \n",
            "4    shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum   \n",
            "5    shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum   \n",
            "6    shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum   \n",
            "7     shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum   \n",
            "8     shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum   \n",
            "9     shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum   \n",
            "10    shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum   \n",
            "11    shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum   \n",
            "12    shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum   \n",
            "13  shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   \n",
            "14  shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   \n",
            "15  shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   \n",
            "16  shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   \n",
            "17  shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   \n",
            "18     shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum   \n",
            "19     shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum   \n",
            "20     shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum   \n",
            "21     shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum   \n",
            "22  shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Bil...   \n",
            "23  shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Bil...   \n",
            "24  shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Bil...   \n",
            "25  shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum   \n",
            "26  shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum   \n",
            "27  shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bi...   \n",
            "\n",
            "                                               group2  meandiff   p-adj  \\\n",
            "0     shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum    -0.024  0.9999   \n",
            "1   shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum    -0.016  1.0000   \n",
            "2      shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum     0.016  1.0000   \n",
            "3   shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Bil...     0.040  0.9980   \n",
            "4   shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum    -0.032  0.9995   \n",
            "5   shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bi...    -0.064  0.9670   \n",
            "6    shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum     0.016  1.0000   \n",
            "7   shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum     0.008  1.0000   \n",
            "8      shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum     0.040  0.9980   \n",
            "9   shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Bil...     0.064  0.9670   \n",
            "10  shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum    -0.008  1.0000   \n",
            "11  shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bi...    -0.040  0.9980   \n",
            "12   shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum     0.040  0.9980   \n",
            "13     shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum     0.032  0.9995   \n",
            "14  shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Bil...     0.056  0.9845   \n",
            "15  shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum    -0.016  1.0000   \n",
            "16  shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bi...    -0.048  0.9938   \n",
            "17   shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum     0.032  0.9995   \n",
            "18  shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Bil...     0.024  0.9999   \n",
            "19  shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum    -0.048  0.9938   \n",
            "20  shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bi...    -0.080  0.8962   \n",
            "21   shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum    -0.000  1.0000   \n",
            "22  shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum    -0.072  0.9383   \n",
            "23  shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bi...    -0.104  0.6898   \n",
            "24   shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum    -0.024  0.9999   \n",
            "25  shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bi...    -0.032  0.9995   \n",
            "26   shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum     0.048  0.9938   \n",
            "27   shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum     0.080  0.8962   \n",
            "\n",
            "     lower   upper  reject  \n",
            "0  -0.2119  0.1639   False  \n",
            "1  -0.2039  0.1719   False  \n",
            "2  -0.1719  0.2039   False  \n",
            "3  -0.1479  0.2279   False  \n",
            "4  -0.2199  0.1559   False  \n",
            "5  -0.2519  0.1239   False  \n",
            "6  -0.1719  0.2039   False  \n",
            "7  -0.1799  0.1959   False  \n",
            "8  -0.1479  0.2279   False  \n",
            "9  -0.1239  0.2519   False  \n",
            "10 -0.1959  0.1799   False  \n",
            "11 -0.2279  0.1479   False  \n",
            "12 -0.1479  0.2279   False  \n",
            "13 -0.1559  0.2199   False  \n",
            "14 -0.1319  0.2439   False  \n",
            "15 -0.2039  0.1719   False  \n",
            "16 -0.2359  0.1399   False  \n",
            "17 -0.1559  0.2199   False  \n",
            "18 -0.1639  0.2119   False  \n",
            "19 -0.2359  0.1399   False  \n",
            "20 -0.2679  0.1079   False  \n",
            "21 -0.1879  0.1879   False  \n",
            "22 -0.2599  0.1159   False  \n",
            "23 -0.2919  0.0839   False  \n",
            "24 -0.2119  0.1639   False  \n",
            "25 -0.2199  0.1559   False  \n",
            "26 -0.1399  0.2359   False  \n",
            "27 -0.1079  0.2679   False  \n",
            "\n",
            "Correlation Matrix:\n",
            "                   Overall Score  Relevance Score  Conciseness Score  \\\n",
            "Overall Score           1.000000     6.593765e-01           0.576532   \n",
            "Relevance Score         0.659377     1.000000e+00           0.500741   \n",
            "Conciseness Score       0.576532     5.007412e-01           1.000000   \n",
            "Fluency Score           0.438090    -1.533271e-01          -0.113539   \n",
            "Accuracy Score          0.646419     6.307298e-01           0.529359   \n",
            "Coherence Score         0.630659    -3.481778e-16           0.099675   \n",
            "\n",
            "                   Fluency Score  Accuracy Score  Coherence Score  \n",
            "Overall Score           0.438090        0.646419     6.306587e-01  \n",
            "Relevance Score        -0.153327        0.630730    -3.481778e-16  \n",
            "Conciseness Score      -0.113539        0.529359     9.967534e-02  \n",
            "Fluency Score           1.000000       -0.129031     5.070585e-01  \n",
            "Accuracy Score         -0.129031        1.000000     7.824149e-02  \n",
            "Coherence Score         0.507058        0.078241     1.000000e+00  \n",
            "\n",
            "PCA Explained Variance Ratio:\n",
            "[4.81789411e-01 2.92256046e-01 8.98351339e-02 7.55677735e-02\n",
            " 6.05516352e-02 2.75988161e-18]\n",
            "\n",
            "Kruskal-Wallis and Dunn's Test Results (example for Overall Score):\n",
            "Kruskal-Wallis: KruskalResult(statistic=6.942266360182854, pvalue=0.4349157565114443)\n",
            "Dunn's Test:\n",
            "None\n",
            "\n",
            "Visualizations complete. Check the generated PNG files for updated plots.\n",
            "\n",
            "Descriptive Statistics:\n",
            "                                                   Overall Score            \\\n",
            "                                                            mean       std   \n",
            "model_name                                                                   \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum           2.464  0.180000   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum            2.440  0.173205   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum          2.448  0.119443   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum             2.480  0.230940   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum         2.504  0.258972   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum          2.432  0.221209   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...         2.400  0.230940   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum           2.480  0.276887   \n",
            "\n",
            "                                                             Relevance Score  \\\n",
            "                                                    min  max            mean   \n",
            "model_name                                                                     \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum    2.0  2.8            1.28   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum     1.8  2.8            1.08   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   2.2  2.8            1.16   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum      2.2  3.4            1.16   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum  1.8  3.0            1.44   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum   1.8  3.0            1.20   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...  1.8  3.0            1.28   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum    2.0  3.2            1.40   \n",
            "\n",
            "                                                                      \\\n",
            "                                                         std min max   \n",
            "model_name                                                             \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum    0.458258   1   2   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum     0.276887   1   2   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   0.374166   1   2   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum      0.374166   1   2   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum  0.506623   1   2   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum   0.577350   1   3   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...  0.458258   1   2   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum    0.577350   1   3   \n",
            "\n",
            "                                                   Conciseness Score  \\\n",
            "                                                                mean   \n",
            "model_name                                                             \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum                3.04   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum                 2.96   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum               3.04   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum                  3.04   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum              3.12   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum               3.08   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...              3.00   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum                3.08   \n",
            "\n",
            "                                                              ...  \\\n",
            "                                                         std  ...   \n",
            "model_name                                                    ...   \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum    0.200000  ...   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum     0.200000  ...   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   0.200000  ...   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum      0.200000  ...   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum  0.331662  ...   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum   0.276887  ...   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...  0.000000  ...   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum    0.276887  ...   \n",
            "\n",
            "                                                   Fluency Score      \\\n",
            "                                                             min max   \n",
            "model_name                                                             \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum               3   4   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum                3   4   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum              3   4   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum                 4   5   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum             2   4   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum              2   4   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...             2   4   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum               3   4   \n",
            "\n",
            "                                                   Accuracy Score            \\\n",
            "                                                             mean       std   \n",
            "model_name                                                                    \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum             1.08  0.276887   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum              1.04  0.200000   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum            1.04  0.200000   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum               1.08  0.276887   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum           1.20  0.408248   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum            1.08  0.276887   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...           1.04  0.200000   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum             1.20  0.408248   \n",
            "\n",
            "                                                           Coherence Score  \\\n",
            "                                                   min max            mean   \n",
            "model_name                                                                   \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum     1   2            2.96   \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum      1   2            3.16   \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum    1   2            3.04   \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum       1   2            3.08   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum   1   2            3.00   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum    1   2            2.96   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...   1   2            2.92   \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum     1   2            2.88   \n",
            "\n",
            "                                                                      \n",
            "                                                         std min max  \n",
            "model_name                                                            \n",
            "shng2025/GPT-Valkyrie_LN-124m__AttnOnly__Billsum    0.351188   2   4  \n",
            "shng2025/GPT-Valkyrie_LN-124m__FFNonly__Billsum     0.472582   2   4  \n",
            "shng2025/GPT-Valkyrie_LN-124m__baseModel__Billsum   0.351188   2   4  \n",
            "shng2025/GPT-Valkyrie_LN-124m__noNorm__Billsum      0.493288   2   4  \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__AttnOnly__Billsum  0.577350   2   4  \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__FFNonly__Billsum   0.351188   2   4  \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__baseModel__Bil...  0.493288   2   4  \n",
            "shng2025/GPT-Valkyrie_RMSN-124m__noNorm__Billsum    0.331662   2   3  \n",
            "\n",
            "[8 rows x 24 columns]\n",
            "\n",
            "Analysis complete. Check the generated PNG files for visualizations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kewxQHqpMP9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}